# Turn-Signal-Detection-for-Vehicles
專案進度報告-第六組
1.	概述
1.1	團隊成員
許育豪 613415170、鄭朝元 613415106、余謝宗倫 613415123、黃冠彰 613415140、林群振 613415145、黃鼎鈞 613415152。
1.2	題目簡介
   本專題旨為車輛方向燈辨識（Turn Signal Detection for Vehicles），藉由電腦視覺技術自動分析監視器畫面中車輛是否於轉彎時正確打方向燈。系統將應用於交通違規分析、智慧交通管理或行車安全輔助系統中，提升交通監控的自動化與效率。
1.3	任務分配
1.3.1	資料整理
鄭朝元 613415106、余謝宗倫 613415123
1.3.2	資料標註
許育豪 613415170、黃冠彰 613415140、林群振 613415145
1.3.3	模型訓練
黃鼎鈞 613415152
2.	專案資料
2.1	資料來源
    本專題所使用的車輛影像與影片資料，涵蓋多種車型、白天與夜間場景、不同轉彎角度及方向燈使用情況。整體資料規劃如下：
	Car_img_dataset.zip（20.3 GB）：靜態影像資料，包含多張來自監視器畫面的車輛圖片，供方向燈亮滅判別模型訓練使用。
	video_dataset.zip（20.7 GB）：影片資料，記錄車輛行駛與轉彎過程，主要應用於行為辨識與時序判斷模型。
	車燈亮暗標記：標註每張圖像或影片中車輛方向燈的亮滅狀態。
	燈位置標記.zip（34.8 MB）：提供每輛車在畫面中的方向燈位置座標（bounding box）。
2.2	資料處理流程
    將影片切割為固定長度影格序列存為照片，使用 LabelImg 和自訂工具，針對影像與影片逐幀標記方向燈位置與亮暗狀態。資料格式轉換轉為 YOLO。
2.3	訓練與測試資料分配策略
    總dataset 為5000筆原始圖片及標註資料，資料分配策略為訓練集70%、驗證集15%及測試集：15%，類別分別為左轉打燈、右轉打燈及轉彎未打燈。
3.	專案模型：
3.1	模型來源
    本專題預計採用 YOLOv7（You Only Look Once version 7）作為核心物件偵測模型，用於偵測車輛方向燈的位置與亮滅狀態。YOLOv7 為目前主流之即時物件偵測架構，具備良好的準確率與推論速度，適合應用於交通監視器畫面中小型目標（如方向燈）的辨識任務。
3.2	訓練類別
    目前模型尚未進行訓練，團隊預計後續進行以下修改以強化模型表現，左轉打燈、右轉打燈及轉彎未打燈。
3.3	訓練方法
訓練流程將依照 YOLOv7 官方訓練流程進行，初步規劃如下：
	輸入尺寸：640 × 640
	Optimizer：SGD 或 AdamW
	Batch size：依據 GPU 容量（使用 Colab Pro/Enterprise）
	訓練次數：預設 50~100 epochs
	損失函數：BCE Loss + CIoU Loss
4.	目前進度
    目前仍在進行標註與資料整合作業，因此尚未開始模型訓練。資瞭標註已完成1535筆並訓練模型。
